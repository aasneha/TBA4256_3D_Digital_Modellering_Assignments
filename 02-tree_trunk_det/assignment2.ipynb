{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa0d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "import os, glob, re, csv, time, math, random\n",
    "import numpy as np\n",
    "import laspy\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bcd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variables\n",
    "\"\"\"\n",
    "# Files paths \n",
    "input_las = \"Assignment02 - Cloud.las\"\n",
    "downsampled_las = \"Downsampled_cloud.las\"\n",
    "filtered_las = \"GroundFiltered_cloud.las\"\n",
    "slices_dir = \"Slices_las\"\n",
    "accumulated_dir = \"Accumulated_pairs\"               \n",
    "dbscan_dir = \"DBSCAN_filtered\"                      \n",
    "ransac_dir = \"RANSAC_results\"                       \n",
    "trees_dir = \"Trees\"\n",
    "detected_circles_csv = \"detected_circles.csv\"\n",
    "\n",
    "# Down sampling voxel size\n",
    "voxel_size = 0.035\n",
    "\n",
    "# Ground filtering\n",
    "distance_threshold = 0.05                           \n",
    "num_iterations = 2000                               \n",
    "height_above_ground = 0.15\n",
    "\n",
    "# Slice parameters\n",
    "slice_thickness = 0.5\n",
    "start_height = 0.5\n",
    "end_height = 3.5\n",
    "\n",
    "# DBSCAN clustering\n",
    "dbscan_eps = 0.8                                    \n",
    "dbscan_min_points = 8                               \n",
    "max_points_for_dbscan = 100_000 \n",
    "\n",
    "\n",
    "#RANSAC circle fitting\n",
    "ransac_iterations = 1000                            \n",
    "ransac_residual_threshold = 0.012                   \n",
    "valid_cluster_size = (15, 400)                      \n",
    "valid_radius_range = (0.05, 1.5)    \n",
    "ransac_min_inliers = 20                \n",
    "\n",
    "# Tree grouping and export\n",
    "min_slices_per_tree = 3                             \n",
    "radius_margin_factor = 1.8                          \n",
    "z_margin = 0.15                                   \n",
    "min_points_per_trunk = 100                       \n",
    "z_scale_for_grouping = 0.2                        \n",
    "eps_xyz = 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e84159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read and write to file methodes\n",
    "\"\"\"\n",
    "\n",
    "def read_las_points(filepath):\n",
    "    las = laspy.read(filepath)\n",
    "    points = np.vstack((las.x, las.y, las.z)).T\n",
    "    return las, points\n",
    "\n",
    "\n",
    "def write_las_points(filepath, points, template_las, add_height=True):\n",
    "    header = laspy.LasHeader(point_format=template_las.header.point_format.id,\n",
    "                             version=template_las.header.version)\n",
    "    las_out = laspy.LasData(header)\n",
    "    las_out.x = points[:, 0]\n",
    "    las_out.y = points[:, 1]\n",
    "    las_out.z = points[:, 2]\n",
    "\n",
    "    if template_las.header.parse_crs() is not None:\n",
    "        las_out.header.add_crs(template_las.header.parse_crs())\n",
    "\n",
    "    if add_height:\n",
    "        las_out.add_extra_dim(laspy.ExtraBytesParams(name=\"Height\", type=np.float32))\n",
    "        las_out.Height = points[:, 2]\n",
    "\n",
    "    las_out.write(filepath)\n",
    "    return las_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebc8739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original point count: 22176864\n",
      "Downsampled point count: 12269114\n",
      "Point cloud size reduced by 44.68%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Downsample point cloud using voxel downsampling\n",
    "\"\"\"\n",
    "\n",
    "# Read the LAS file \n",
    "las, points = read_las_points(input_las)\n",
    "print(\"Original point count:\", len(points))\n",
    "\n",
    "# Convert to Open3D point cloud \n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "# Voxel downsampling\n",
    "pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "down_pts = np.asarray(pcd_down.points)\n",
    "print(\"Downsampled point count:\", len(down_pts))\n",
    "\n",
    "reduction = (1 - len(down_pts) / len(points)) * 100\n",
    "print(f\"Point cloud size reduced by {reduction:.2f}%\")\n",
    "\n",
    "las_down = write_las_points(downsampled_las, down_pts, las)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7e0385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated ground plane: 0.0088x + -0.0213y + 0.9997z + 1.4365 = 0\n",
      "Ground inliers: 704032 / 12269114 points\n",
      "Filtered 2715497 ground points, kept 19461367 above plane.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ground filtering using RANSAC plane fitting\n",
    "\"\"\"\n",
    "pcd_down = o3d.geometry.PointCloud()\n",
    "pcd_down.points = o3d.utility.Vector3dVector(down_pts)\n",
    "\n",
    "plane_model, inliers = pcd_down.segment_plane(\n",
    "    distance_threshold=distance_threshold,\n",
    "    ransac_n=3,\n",
    "    num_iterations=num_iterations\n",
    ")\n",
    "\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Estimated ground plane: {a:.4f}x + {b:.4f}y + {c:.4f}z + {d:.4f} = 0\")\n",
    "print(f\"Ground inliers: {len(inliers)} / {len(down_pts)} points\")\n",
    "\n",
    "all_points = np.asarray(pcd.points)  \n",
    "distances_all = a * all_points[:, 0] + b * all_points[:, 1] + c * all_points[:, 2] + d\n",
    "norm_factor = math.sqrt(a**2 + b**2 + c**2)\n",
    "z_local_all = distances_all / norm_factor\n",
    "\n",
    "mask = z_local_all > height_above_ground\n",
    "\n",
    "filtered_points = all_points[mask]\n",
    "removed_count = len(all_points) - len(filtered_points)\n",
    "print(f\"Filtered {removed_count} ground points, kept {len(filtered_points)} above plane.\")\n",
    "\n",
    "las_filtered = write_las_points(filtered_las, filtered_points, las)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af99089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished slicing. 6 slices saved in 'Slices_las' folder.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Slice selection and processing\n",
    "\"\"\"\n",
    "os.makedirs(slices_dir, exist_ok=True)\n",
    "\n",
    "las, points = read_las_points(filtered_las)\n",
    "\n",
    "distances = a * points[:, 0] + b * points[:, 1] + c * points[:, 2] + d\n",
    "norm_factor = math.sqrt(a**2 + b**2 + c**2)\n",
    "z_local = distances / norm_factor  \n",
    "\n",
    "slice_levels = np.arange(start_height, end_height, slice_thickness)\n",
    "\n",
    "saved_count = 0\n",
    "for i, z_level in enumerate(slice_levels):\n",
    "    lower, upper = z_level, z_level + slice_thickness\n",
    "    mask = (z_local >= lower) & (z_local < upper)\n",
    "    slice_pts = points[mask]  \n",
    "    if len(slice_pts) == 0:\n",
    "        continue\n",
    "\n",
    "    out_path = os.path.join(slices_dir, f\"slice_{i+1:02d}.laz\")\n",
    "    write_las_points(out_path, slice_pts, las)\n",
    "    saved_count += 1\n",
    "\n",
    "print(f\"Finished slicing. {saved_count} slices saved in '{slices_dir}' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f552ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created accumulated pair: Accumulated_pairs\\accumulated_01.laz (475772 pts)\n",
      "Created accumulated pair: Accumulated_pairs\\accumulated_02.laz (460120 pts)\n",
      "Created accumulated pair: Accumulated_pairs\\accumulated_03.laz (548845 pts)\n",
      "Created accumulated pair: Accumulated_pairs\\accumulated_04.laz (742834 pts)\n",
      "Created accumulated pair: Accumulated_pairs\\accumulated_05.laz (1045443 pts)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Accumulate points between pairs of slices onto 2D planes\n",
    "\"\"\"\n",
    "slice_files = sorted(glob.glob(os.path.join(slices_dir, \"slice_*.laz\")))\n",
    "\n",
    "os.makedirs(accumulated_dir, exist_ok=True)\n",
    "\n",
    "for i in range(len(slice_files) - 1):\n",
    "    f1, f2 = slice_files[i], slice_files[i + 1]\n",
    "    las1, pts1 = read_las_points(f1)\n",
    "    las2, pts2 = read_las_points(f2)\n",
    "\n",
    "    # Merge the two slices\n",
    "    combined = np.vstack((pts1, pts2))\n",
    "    combined[:, 2] = 0  # project to 2D plane (ignore z)\n",
    "    \n",
    "    # Save new accumulated file\n",
    "    out_path = os.path.join(accumulated_dir, f\"accumulated_{i+1:02d}.laz\")\n",
    "    write_las_points(out_path, combined, las1)\n",
    "    print(f\"Created accumulated pair: {out_path} ({len(combined)} pts)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a810c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustering accumulated_01.laz (100000 points)\n",
      " → Found 203 clusters (+ 265 noise points)\n",
      "Saved DBSCAN-filtered slice: DBSCAN_filtered\\accumulated_01_dbscan.laz\n",
      "\n",
      "Clustering accumulated_02.laz (100000 points)\n",
      " → Found 206 clusters (+ 253 noise points)\n",
      "Saved DBSCAN-filtered slice: DBSCAN_filtered\\accumulated_02_dbscan.laz\n",
      "\n",
      "Clustering accumulated_03.laz (100000 points)\n",
      " → Found 212 clusters (+ 330 noise points)\n",
      "Saved DBSCAN-filtered slice: DBSCAN_filtered\\accumulated_03_dbscan.laz\n",
      "\n",
      "Clustering accumulated_04.laz (100000 points)\n",
      " → Found 218 clusters (+ 455 noise points)\n",
      "Saved DBSCAN-filtered slice: DBSCAN_filtered\\accumulated_04_dbscan.laz\n",
      "\n",
      "Clustering accumulated_05.laz (100000 points)\n",
      " → Found 228 clusters (+ 472 noise points)\n",
      "Saved DBSCAN-filtered slice: DBSCAN_filtered\\accumulated_05_dbscan.laz\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DBSCAN Clustering of accumulated slices with random downsampling\n",
    "\"\"\"\n",
    "\n",
    "os.makedirs(dbscan_dir, exist_ok=True)\n",
    "accum_files = sorted(glob.glob(os.path.join(accumulated_dir, \"accumulated_*.laz\")))\n",
    "\n",
    "# DBSCAN-parametre\n",
    "for f in accum_files:\n",
    "    las, pts = read_las_points(f)\n",
    "    xy = pts[:, :2]\n",
    "\n",
    "    if len(xy) < 20:\n",
    "        continue\n",
    "\n",
    "    if len(xy) > max_points_for_dbscan:\n",
    "        idx = np.random.choice(len(xy), max_points_for_dbscan, replace=False)\n",
    "        xy = xy[idx]\n",
    "\n",
    "    print(f\"\\nClustering {os.path.basename(f)} ({len(xy)} points)\")\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    xy_3d = np.hstack((xy, np.zeros((len(xy), 1))))\n",
    "    pcd.points = o3d.utility.Vector3dVector(xy_3d)\n",
    "\n",
    "    labels = np.array(pcd.cluster_dbscan(eps=dbscan_eps, min_points=dbscan_min_points, print_progress=False))\n",
    "    num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "    print(f\" → Found {num_clusters} clusters (+ {np.sum(labels==-1)} noise points)\")\n",
    "\n",
    "    # Make colors for all points\n",
    "    max_label = labels.max()\n",
    "    colors = plt.get_cmap(\"tab20\")(labels / (max_label + 1 if max_label >= 0 else 1))\n",
    "    colors[labels < 0] = [0, 0, 0, 1]  # black for noise\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axs[0].scatter(xy[:, 0], xy[:, 1], s=1, color=\"gray\")\n",
    "    axs[0].set_title(\"Before DBSCAN\")\n",
    "    axs[0].axis(\"equal\")\n",
    "\n",
    "    axs[1].scatter(xy[:, 0], xy[:, 1], s=2, color=colors)\n",
    "    axs[1].set_title(f\"After DBSCAN ({num_clusters} clusters)\")\n",
    "    axs[1].axis(\"equal\")\n",
    "\n",
    "    plt.suptitle(os.path.basename(f))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(dbscan_dir, os.path.basename(f).replace(\".laz\", \"_dbscan_vis.png\")))\n",
    "    plt.close()\n",
    "\n",
    "    # Remove noise points and save filtered slice\n",
    "    mask = labels != -1\n",
    "    filtered_pts = xy[mask]\n",
    "    filtered_3d = np.hstack((filtered_pts, np.zeros((len(filtered_pts), 1))))\n",
    "    out_path = os.path.join(dbscan_dir, os.path.basename(f).replace(\".laz\", \"_dbscan.laz\"))\n",
    "    write_las_points(out_path, filtered_3d, las)\n",
    "    print(f\"Saved DBSCAN-filtered slice: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbc0760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing accumulated_01_dbscan.laz ...\n",
      " → Found 231 clusters\n",
      "Rejected circle (r=17.97 m) – outside valid range\n",
      "Rejected circle (r=30.51 m) – outside valid range\n",
      "Rejected circle (r=0.03 m) – outside valid range\n",
      "Rejected circle (r=11.49 m) – outside valid range\n",
      "Rejected circle (r=7.93 m) – outside valid range\n",
      " → Detected 81 valid circles in this layer.\n",
      "\n",
      "Processing accumulated_02_dbscan.laz ...\n",
      " → Found 266 clusters\n",
      "Rejected circle (r=6.53 m) – outside valid range\n",
      "Rejected circle (r=0.03 m) – outside valid range\n",
      "Rejected circle (r=4.45 m) – outside valid range\n",
      "Rejected circle (r=42.42 m) – outside valid range\n",
      "Rejected circle (r=2.00 m) – outside valid range\n",
      "Rejected circle (r=4.73 m) – outside valid range\n",
      " → Detected 86 valid circles in this layer.\n",
      "\n",
      "Processing accumulated_03_dbscan.laz ...\n",
      " → Found 306 clusters\n",
      "Rejected circle (r=2.02 m) – outside valid range\n",
      "Rejected circle (r=23.77 m) – outside valid range\n",
      "Rejected circle (r=4.38 m) – outside valid range\n",
      "Rejected circle (r=0.03 m) – outside valid range\n",
      " → Detected 108 valid circles in this layer.\n",
      "\n",
      "Processing accumulated_04_dbscan.laz ...\n",
      " → Found 335 clusters\n",
      "Rejected circle (r=1.83 m) – outside valid range\n",
      "Rejected circle (r=5.37 m) – outside valid range\n",
      "Rejected circle (r=3.59 m) – outside valid range\n",
      "Rejected circle (r=3.17 m) – outside valid range\n",
      "Rejected circle (r=3.24 m) – outside valid range\n",
      "Rejected circle (r=8.30 m) – outside valid range\n",
      "Rejected circle (r=2.14 m) – outside valid range\n",
      "Rejected circle (r=13.01 m) – outside valid range\n",
      "Rejected circle (r=2.63 m) – outside valid range\n",
      "Rejected circle (r=7.15 m) – outside valid range\n",
      "Rejected circle (r=1.57 m) – outside valid range\n",
      "Rejected circle (r=2.40 m) – outside valid range\n",
      "Rejected circle (r=3.73 m) – outside valid range\n",
      "Rejected circle (r=6.82 m) – outside valid range\n",
      "Rejected circle (r=0.04 m) – outside valid range\n",
      "Rejected circle (r=4.60 m) – outside valid range\n",
      " → Detected 101 valid circles in this layer.\n",
      "\n",
      "Processing accumulated_05_dbscan.laz ...\n",
      " → Found 370 clusters\n",
      "Rejected circle (r=14.83 m) – outside valid range\n",
      "Rejected circle (r=1.59 m) – outside valid range\n",
      "Rejected circle (r=2.28 m) – outside valid range\n",
      "Rejected circle (r=12.00 m) – outside valid range\n",
      "Rejected circle (r=6.49 m) – outside valid range\n",
      "Rejected circle (r=2.41 m) – outside valid range\n",
      "Rejected circle (r=4.63 m) – outside valid range\n",
      "Rejected circle (r=5.14 m) – outside valid range\n",
      "Rejected circle (r=9.44 m) – outside valid range\n",
      " → Detected 106 valid circles in this layer.\n",
      "\n",
      " Done! Saved all results to 'RANSAC_results' and 'RANSAC_results\\detected_circles.csv'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "RANSAC Circle Fitting on DBSCAN-filtered slices\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def fit_circle(p1, p2, p3):\n",
    "    #Calculate circle center and radius from three points.\n",
    "    temp = p2[0]**2 + p2[1]**2\n",
    "    bc = (p1[0]**2 + p1[1]**2 - temp) / 2\n",
    "    cd = (temp - p3[0]**2 - p3[1]**2) / 2\n",
    "    det = (p1[0] - p2[0]) * (p2[1] - p3[1]) - (p2[0] - p3[0]) * (p1[1] - p2[1])\n",
    "    if abs(det) < 1e-6:\n",
    "        return None\n",
    "    cx = (bc * (p2[1] - p3[1]) - cd * (p1[1] - p2[1])) / det\n",
    "    cy = ((p1[0] - p2[0]) * cd - (p2[0] - p3[0]) * bc) / det\n",
    "    r = math.sqrt((cx - p1[0])**2 + (cy - p1[1])**2)\n",
    "    return cx, cy, r\n",
    "\n",
    "\n",
    "def ransac_circle(points, iterations, threshold):\n",
    "    #RANSAC for circle fitting\n",
    "    best_inliers, best_circle = [], None\n",
    "    n = len(points)\n",
    "    if n < 3:\n",
    "        return None, []\n",
    "    for _ in range(iterations):\n",
    "        p1, p2, p3 = points[np.random.choice(n, 3, replace=False)]\n",
    "        circle = fit_circle(p1, p2, p3)\n",
    "        if circle is None:\n",
    "            continue\n",
    "        cx, cy, r = circle\n",
    "        dists = np.sqrt((points[:, 0] - cx)**2 + (points[:, 1] - cy)**2)\n",
    "        inliers = np.where(np.abs(dists - r) < threshold)[0]\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers, best_circle = inliers, (cx, cy, r)\n",
    "    return best_circle, best_inliers\n",
    "\n",
    "\n",
    "def run_dbscan(xy, eps=0.18, min_points=19):\n",
    "    #Run DBSCAN clustering on 2D points.\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.column_stack((xy, np.zeros(len(xy)))))\n",
    "    return np.array(pcd.cluster_dbscan(eps=eps, min_points=min_points, print_progress=False))\n",
    "\n",
    "\n",
    "def plot_clusters(ax, xy, title):\n",
    "    ax.scatter(xy[:, 0], xy[:, 1], s=1, color=\"lightgray\")\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"equal\")\n",
    "\n",
    "\n",
    "# Main RANSAC processing\n",
    "\n",
    "os.makedirs(ransac_dir, exist_ok=True)\n",
    "filtered_files = sorted(glob.glob(os.path.join(dbscan_dir, \"accumulated_*_dbscan.laz\")))\n",
    "\n",
    "detected_circles = []\n",
    "\n",
    "for f in filtered_files:\n",
    "    las, pts = read_las_points(f)\n",
    "    xy = pts[:, :2]\n",
    "    if len(xy) < 20:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing {os.path.basename(f)} ...\")\n",
    "\n",
    "    # DBSCAN for separating clusters\n",
    "    labels = run_dbscan(xy, eps=0.18, min_points=19)\n",
    "    num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    print(f\" → Found {num_clusters} clusters\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    plot_clusters(ax, xy, f\"{os.path.basename(f)} — {num_clusters} clusters\")\n",
    "\n",
    "    total_circles = 0\n",
    "\n",
    "    # RANSAC per cluster\n",
    "    for c in range(num_clusters):\n",
    "        cluster_pts = xy[labels == c]\n",
    "        n_points = len(cluster_pts)\n",
    "        if n_points < valid_cluster_size[0] or n_points > valid_cluster_size[1]:\n",
    "            continue\n",
    "\n",
    "        circle, inliers = ransac_circle(cluster_pts, ransac_iterations, ransac_residual_threshold)\n",
    "        if (circle is None\n",
    "            or len(inliers) < ransac_min_inliers):\n",
    "            continue\n",
    "\n",
    "        cx, cy, r = circle\n",
    "        if not (valid_radius_range[0] <= r <= valid_radius_range[1]):\n",
    "            print(f\"Rejected circle (r={r:.2f} m) – outside valid range\")\n",
    "            continue\n",
    "\n",
    "        detected_circles.append([os.path.basename(f), c, cx, cy, r, len(inliers)])\n",
    "        total_circles += 1\n",
    "\n",
    "        ax.scatter(cluster_pts[inliers, 0], cluster_pts[inliers, 1], s=3, color=\"red\")\n",
    "        circ = plt.Circle((cx, cy), r, color=\"blue\", fill=False, lw=1)\n",
    "        ax.add_patch(circ)\n",
    "        ax.text(cx, cy, f\"{r:.2f}\", fontsize=6, color=\"blue\")\n",
    "\n",
    "    ax.set_title(f\"{os.path.basename(f)} — {total_circles} fitted circles\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ransac_dir, os.path.basename(f).replace(\".laz\", \"_circles.png\")))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\" → Detected {total_circles} valid circles in this layer.\")\n",
    "\n",
    "# Save results\n",
    "csv_path = os.path.join(ransac_dir, detected_circles_csv)\n",
    "with open(csv_path, \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"File\", \"ClusterID\", \"CenterX\", \"CenterY\", \"Radius_m\", \"Inliers\"])\n",
    "    writer.writerows(detected_circles)\n",
    "\n",
    "print(f\"\\n Done! Saved all results to '{ransac_dir}' and '{csv_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c823eb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\aasne\\AppData\\Local\\Temp\\ipykernel_19388\\3263201343.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncsv_path = os.path.join(ransac_dir, detected_circles_csv)\\nfiltered_cloud_path = filtered_las\\nos.makedirs(trees_dir, exist_ok=True)\\n\\n# krav for at en klynge skal være et tre\\nmin_slices_per_tree = 3\\n\\n# syl/BB-parametre\\nradius_margin_factor = 1.8   # utvid radius litt for å få med alt\\nz_margin = 0.15               # legg til litt høyde-margin (m)\\n\\n# klynging av (x,y,z_slice) – bruk Open3D DBSCAN på 3D-koordinater\\neps_xyz = 3     # meter (tuning: 0.25–0.50 vanligvis bra)\\nmin_points_dbscan = min_slices_per_tree  # må dukke opp i minst N slices\\n\\n# --- les detected circles (ett rad per slice/cluster) ---\\nif not os.path.exists(csv_path):\\n    raise FileNotFoundError(f\"Fant ikke {csv_path}. Kjør RANSAC-delen som lager CSV først.\")\\n\\nrows = []\\nwith open(csv_path, newline=\"\") as f:\\n    reader = csv.DictReader(f)\\n    for r in reader:\\n        rows.append(r)\\n\\nif not rows:\\n    raise RuntimeError(\"Ingen sirkler i CSV. Sjekk RANSAC-resultatene.\")\\n\\n# --- rekonstruer z-høyder for hver \\'accumulated_XX\\' ---\\n# vi brukte \\'accumulated_{i:02d}\\' der i = 1..(n-1), hvert par dekker to slices\\n# beregn base z_min fra filtered_las (slik slicing ble gjort)\\n_, filt_pts_all = read_las_points(filtered_cloud_path)\\nzmin_filtered = float(np.min(filt_pts_all[:, 2]))\\n\\n# slice_levels ble tidligere: np.arange(z_min + start_height, z_min + end_height, slice_thickness)\\nslice_levels = np.arange(zmin_filtered + start_height, zmin_filtered + end_height, slice_thickness)\\n\\ndef pair_index_from_filename(basename):\\n    # forventer \"accumulated_XX_dbscan.laz\" i CSV\\'en (File-kolonnen)\\n    m = re.search(r\"accumulated_(\\\\d+)\", basename)\\n    if not m:\\n        return None\\n    return int(m.group(1))  # 1-basert index\\n\\ndef z_bounds_for_pair(idx_1based):\\n    # pair i dekker slice i og i+1\\n    i = idx_1based - 1  # 0-basert\\n    if i < 0 or i+1 >= len(slice_levels):\\n        # fallback: bruk min/max vi har\\n        low = slice_levels.max()\\n        up = low + 2*slice_thickness\\n        return float(low), float(up)\\n    low = slice_levels[i]\\n    up  = slice_levels[i] + 2*slice_thickness\\n    return float(low), float(up)\\n\\n# bygg punktliste for klynging og metadata\\ncenters_xy = []\\ncenters_xyz_for_cluster = []  # (x, y, z_center_scaled)\\ncircle_meta = []              # per rad: dict med alt vi trenger\\n\\nz_scale = 0.2  # kan senkes hvis du vil at Z skal telle mindre i DBSCAN (f.eks. 0.5)\\n\\nfor r in rows:\\n    fname = r[\"File\"]                   # eks \"accumulated_03_dbscan.laz\"\\n    idx = pair_index_from_filename(fname)\\n    if idx is None: \\n        continue\\n\\n    cx = float(r[\"CenterX\"]); cy = float(r[\"CenterY\"]); rad = float(r[\"Radius_m\"])\\n    z_low, z_up = z_bounds_for_pair(idx)\\n    z_center = 0.5 * (z_low + z_up)\\n\\n    centers_xy.append([cx, cy])\\n    centers_xyz_for_cluster.append([cx, cy, z_center * z_scale])\\n    circle_meta.append({\\n        \"file\": fname,\\n        \"pair_index\": idx,\\n        \"center\": (cx, cy),\\n        \"radius\": rad,\\n        \"z_low\": z_low,\\n        \"z_up\": z_up,\\n        \"z_center\": z_center\\n    })\\n\\ncenters_xy = np.asarray(centers_xy)\\ncenters_xyz_for_cluster = np.asarray(centers_xyz_for_cluster)\\n\\n# --- cluster \"trees\" i (x,y,z_slice) rommet ---\\npcd_centers = o3d.geometry.PointCloud()\\npcd_centers.points = o3d.utility.Vector3dVector(centers_xyz_for_cluster)\\nlabels = np.array(pcd_centers.cluster_dbscan(eps=eps_xyz, min_points=min_points_dbscan, print_progress=False))\\nnum_clusters = len(set(labels)) - (1 if -1 in labels else 0)\\nprint(f\"Tree grouping: {num_clusters} clusters (trees) found; noise points: {(labels==-1).sum()}\")\\n\\n# --- bygg 3D-BB/sylinder for hvert tre ---\\ntrees = []\\ntree_id = 0\\nfor lab in sorted(set(labels)):\\n    if lab < 0:\\n        continue\\n    idxs = np.where(labels == lab)[0]\\n    if len(idxs) < min_slices_per_tree:\\n        continue\\n\\n    sub = [circle_meta[i] for i in idxs]\\n\\n    # robust center og radius\\n    cx = float(np.median([s[\"center\"][0] for s in sub]))\\n    cy = float(np.median([s[\"center\"][1] for s in sub]))\\n    r_med = float(np.median([s[\"radius\"] for s in sub]))\\n\\n    zmin = float(min(s[\"z_low\"] for s in sub)) - z_margin\\n    zmax = float(max(s[\"z_up\"]  for s in sub)) + z_margin\\n\\n    tree_id += 1\\n    trees.append({\\n        \"id\": tree_id,\\n        \"center\": (cx, cy),\\n        \"radius\": r_med,\\n        \"zmin\": zmin,\\n        \"zmax\": zmax,\\n        \"n_slices\": len(sub),\\n        \"pairs\": sorted([s[\"pair_index\"] for s in sub])\\n    })\\n\\nprint(f\"Built BBs for {len(trees)} trees (>= {min_slices_per_tree} slices each).\")\\n\\n# --- eksporter punkter innenfor hver 3D-BB fra filtered_las ---\\nlas_filt, pts_filt = read_las_points(filtered_cloud_path)\\nexported = 0\\nsummary_rows = []\\nmin_points_per_trunk = 100\\n\\nfor t in trees:\\n    cx, cy = t[\"center\"]\\n    r_exp = t[\"radius\"] * radius_margin_factor\\n    zmin = t[\"zmin\"]; zmax = t[\"zmax\"]\\n\\n    dx = pts_filt[:,0] - cx\\n    dy = pts_filt[:,1] - cy\\n    dist = np.sqrt(dx*dx + dy*dy)\\n    z = pts_filt[:,2]\\n\\n    mask = (dist <= r_exp) & (z >= zmin) & (z <= zmax)\\n    trunk_pts = pts_filt[mask]\\n\\n    if trunk_pts.shape[0] < min_points_per_trunk:\\n        print(f\" → Rejected tree {t[\\'id\\']} ({trunk_pts.shape[0]} pts – too few)\")\\n        continue\\n\\n    out_path = os.path.join(trees_dir, f\"tree_{t[\\'id\\']:03d}_trunk.laz\")\\n    write_las_points(out_path, trunk_pts, las_filt)\\n    exported += 1\\n\\n    summary_rows.append({\\n        \"tree_id\": t[\"id\"],\\n        \"center_x\": cx,\\n        \"center_y\": cy,\\n        \"radius_m\": t[\"radius\"],\\n        \"radius_used_m\": r_exp,\\n        \"zmin\": zmin,\\n        \"zmax\": zmax,\\n        \"slices_used\": t[\"n_slices\"],\\n        \"pairs\": t[\"pairs\"],\\n        \"points_exported\": int(trunk_pts.shape[0]),\\n        \"file\": out_path\\n    })\\n\\nprint(f\"Exported {exported} tree trunks to \\'{trees_dir}\\'.\")\\n\\n\\n\\n# litt sanity info\\nif len(trees) < 10:\\n    print(\"Fewer than 10 trees detected. Juster eps_xyz (0.25–0.5), min_slices_per_tree, eller tidligere DBSCAN/RANSAC-parametre.\")\\n\\n\\n# Quick 3D plot of detected trees\\nimport matplotlib.pyplot as plt\\nfrom mpl_toolkits.mplot3d import Axes3D\\n\\nfig = plt.figure(figsize=(8,6))\\nax = fig.add_subplot(111, projection=\\'3d\\')\\n\\nfor t in trees:\\n    cx, cy = t[\"center\"]\\n    zmin, zmax = t[\"zmin\"], t[\"zmax\"]\\n    ax.plot([cx, cx], [cy, cy], [zmin, zmax], color=\\'green\\')\\nax.set_xlabel(\"X\")\\nax.set_ylabel(\"Y\")\\nax.set_zlabel(\"Z\")\\nplt.title(f\"{len(trees)} Detected Trees\")\\nplt.show()\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Where there is a best fitted circle, there should be a tree.\n",
    "Load detected circles (from RANSAC) and prepare for tree grouping\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "csv_path = os.path.join(ransac_dir, detected_circles_csv)\n",
    "filtered_cloud_path = filtered_las\n",
    "os.makedirs(trees_dir, exist_ok=True)\n",
    "\n",
    "# krav for at en klynge skal være et tre\n",
    "min_slices_per_tree = 3\n",
    "\n",
    "# syl/BB-parametre\n",
    "radius_margin_factor = 1.8   # utvid radius litt for å få med alt\n",
    "z_margin = 0.15               # legg til litt høyde-margin (m)\n",
    "\n",
    "# klynging av (x,y,z_slice) – bruk Open3D DBSCAN på 3D-koordinater\n",
    "eps_xyz = 3     # meter (tuning: 0.25–0.50 vanligvis bra)\n",
    "min_points_dbscan = min_slices_per_tree  # må dukke opp i minst N slices\n",
    "\n",
    "# --- les detected circles (ett rad per slice/cluster) ---\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"Fant ikke {csv_path}. Kjør RANSAC-delen som lager CSV først.\")\n",
    "\n",
    "rows = []\n",
    "with open(csv_path, newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for r in reader:\n",
    "        rows.append(r)\n",
    "\n",
    "if not rows:\n",
    "    raise RuntimeError(\"Ingen sirkler i CSV. Sjekk RANSAC-resultatene.\")\n",
    "\n",
    "# --- rekonstruer z-høyder for hver 'accumulated_XX' ---\n",
    "# vi brukte 'accumulated_{i:02d}' der i = 1..(n-1), hvert par dekker to slices\n",
    "# beregn base z_min fra filtered_las (slik slicing ble gjort)\n",
    "_, filt_pts_all = read_las_points(filtered_cloud_path)\n",
    "zmin_filtered = float(np.min(filt_pts_all[:, 2]))\n",
    "\n",
    "# slice_levels ble tidligere: np.arange(z_min + start_height, z_min + end_height, slice_thickness)\n",
    "slice_levels = np.arange(zmin_filtered + start_height, zmin_filtered + end_height, slice_thickness)\n",
    "\n",
    "def pair_index_from_filename(basename):\n",
    "    # forventer \"accumulated_XX_dbscan.laz\" i CSV'en (File-kolonnen)\n",
    "    m = re.search(r\"accumulated_(\\d+)\", basename)\n",
    "    if not m:\n",
    "        return None\n",
    "    return int(m.group(1))  # 1-basert index\n",
    "\n",
    "def z_bounds_for_pair(idx_1based):\n",
    "    # pair i dekker slice i og i+1\n",
    "    i = idx_1based - 1  # 0-basert\n",
    "    if i < 0 or i+1 >= len(slice_levels):\n",
    "        # fallback: bruk min/max vi har\n",
    "        low = slice_levels.max()\n",
    "        up = low + 2*slice_thickness\n",
    "        return float(low), float(up)\n",
    "    low = slice_levels[i]\n",
    "    up  = slice_levels[i] + 2*slice_thickness\n",
    "    return float(low), float(up)\n",
    "\n",
    "# bygg punktliste for klynging og metadata\n",
    "centers_xy = []\n",
    "centers_xyz_for_cluster = []  # (x, y, z_center_scaled)\n",
    "circle_meta = []              # per rad: dict med alt vi trenger\n",
    "\n",
    "z_scale = 0.2  # kan senkes hvis du vil at Z skal telle mindre i DBSCAN (f.eks. 0.5)\n",
    "\n",
    "for r in rows:\n",
    "    fname = r[\"File\"]                   # eks \"accumulated_03_dbscan.laz\"\n",
    "    idx = pair_index_from_filename(fname)\n",
    "    if idx is None: \n",
    "        continue\n",
    "\n",
    "    cx = float(r[\"CenterX\"]); cy = float(r[\"CenterY\"]); rad = float(r[\"Radius_m\"])\n",
    "    z_low, z_up = z_bounds_for_pair(idx)\n",
    "    z_center = 0.5 * (z_low + z_up)\n",
    "\n",
    "    centers_xy.append([cx, cy])\n",
    "    centers_xyz_for_cluster.append([cx, cy, z_center * z_scale])\n",
    "    circle_meta.append({\n",
    "        \"file\": fname,\n",
    "        \"pair_index\": idx,\n",
    "        \"center\": (cx, cy),\n",
    "        \"radius\": rad,\n",
    "        \"z_low\": z_low,\n",
    "        \"z_up\": z_up,\n",
    "        \"z_center\": z_center\n",
    "    })\n",
    "\n",
    "centers_xy = np.asarray(centers_xy)\n",
    "centers_xyz_for_cluster = np.asarray(centers_xyz_for_cluster)\n",
    "\n",
    "# --- cluster \"trees\" i (x,y,z_slice) rommet ---\n",
    "pcd_centers = o3d.geometry.PointCloud()\n",
    "pcd_centers.points = o3d.utility.Vector3dVector(centers_xyz_for_cluster)\n",
    "labels = np.array(pcd_centers.cluster_dbscan(eps=eps_xyz, min_points=min_points_dbscan, print_progress=False))\n",
    "num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f\"Tree grouping: {num_clusters} clusters (trees) found; noise points: {(labels==-1).sum()}\")\n",
    "\n",
    "# --- bygg 3D-BB/sylinder for hvert tre ---\n",
    "trees = []\n",
    "tree_id = 0\n",
    "for lab in sorted(set(labels)):\n",
    "    if lab < 0:\n",
    "        continue\n",
    "    idxs = np.where(labels == lab)[0]\n",
    "    if len(idxs) < min_slices_per_tree:\n",
    "        continue\n",
    "\n",
    "    sub = [circle_meta[i] for i in idxs]\n",
    "\n",
    "    # robust center og radius\n",
    "    cx = float(np.median([s[\"center\"][0] for s in sub]))\n",
    "    cy = float(np.median([s[\"center\"][1] for s in sub]))\n",
    "    r_med = float(np.median([s[\"radius\"] for s in sub]))\n",
    "\n",
    "    zmin = float(min(s[\"z_low\"] for s in sub)) - z_margin\n",
    "    zmax = float(max(s[\"z_up\"]  for s in sub)) + z_margin\n",
    "\n",
    "    tree_id += 1\n",
    "    trees.append({\n",
    "        \"id\": tree_id,\n",
    "        \"center\": (cx, cy),\n",
    "        \"radius\": r_med,\n",
    "        \"zmin\": zmin,\n",
    "        \"zmax\": zmax,\n",
    "        \"n_slices\": len(sub),\n",
    "        \"pairs\": sorted([s[\"pair_index\"] for s in sub])\n",
    "    })\n",
    "\n",
    "print(f\"Built BBs for {len(trees)} trees (>= {min_slices_per_tree} slices each).\")\n",
    "\n",
    "# --- eksporter punkter innenfor hver 3D-BB fra filtered_las ---\n",
    "las_filt, pts_filt = read_las_points(filtered_cloud_path)\n",
    "exported = 0\n",
    "summary_rows = []\n",
    "min_points_per_trunk = 100\n",
    "\n",
    "for t in trees:\n",
    "    cx, cy = t[\"center\"]\n",
    "    r_exp = t[\"radius\"] * radius_margin_factor\n",
    "    zmin = t[\"zmin\"]; zmax = t[\"zmax\"]\n",
    "\n",
    "    dx = pts_filt[:,0] - cx\n",
    "    dy = pts_filt[:,1] - cy\n",
    "    dist = np.sqrt(dx*dx + dy*dy)\n",
    "    z = pts_filt[:,2]\n",
    "\n",
    "    mask = (dist <= r_exp) & (z >= zmin) & (z <= zmax)\n",
    "    trunk_pts = pts_filt[mask]\n",
    "\n",
    "    if trunk_pts.shape[0] < min_points_per_trunk:\n",
    "        print(f\" → Rejected tree {t['id']} ({trunk_pts.shape[0]} pts – too few)\")\n",
    "        continue\n",
    "\n",
    "    out_path = os.path.join(trees_dir, f\"tree_{t['id']:03d}_trunk.laz\")\n",
    "    write_las_points(out_path, trunk_pts, las_filt)\n",
    "    exported += 1\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"tree_id\": t[\"id\"],\n",
    "        \"center_x\": cx,\n",
    "        \"center_y\": cy,\n",
    "        \"radius_m\": t[\"radius\"],\n",
    "        \"radius_used_m\": r_exp,\n",
    "        \"zmin\": zmin,\n",
    "        \"zmax\": zmax,\n",
    "        \"slices_used\": t[\"n_slices\"],\n",
    "        \"pairs\": t[\"pairs\"],\n",
    "        \"points_exported\": int(trunk_pts.shape[0]),\n",
    "        \"file\": out_path\n",
    "    })\n",
    "\n",
    "print(f\"Exported {exported} tree trunks to '{trees_dir}'.\")\n",
    "\n",
    "\n",
    "\n",
    "# litt sanity info\n",
    "if len(trees) < 10:\n",
    "    print(\"Fewer than 10 trees detected. Juster eps_xyz (0.25–0.5), min_slices_per_tree, eller tidligere DBSCAN/RANSAC-parametre.\")\n",
    "\n",
    "\n",
    "# Quick 3D plot of detected trees\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for t in trees:\n",
    "    cx, cy = t[\"center\"]\n",
    "    zmin, zmax = t[\"zmin\"], t[\"zmax\"]\n",
    "    ax.plot([cx, cx], [cy, cy], [zmin, zmax], color='green')\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Z\")\n",
    "plt.title(f\"{len(trees)} Detected Trees\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4568e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Where there is a best fitted circle, there should be a tree.\n",
    "Load detected circles (from RANSAC) and prepare for tree grouping.\n",
    "\"\"\"\n",
    "\n",
    "csv_path = os.path.join(ransac_dir, detected_circles_csv)\n",
    "filtered_cloud_path = filtered_las\n",
    "os.makedirs(trees_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    raise FileNotFoundError(f\"{csv_path} not found. Run RANSAC first.\")\n",
    "\n",
    "with open(csv_path, newline=\"\") as f:\n",
    "    rows = list(csv.DictReader(f))\n",
    "if not rows:\n",
    "    raise RuntimeError(\"No detected circles found in CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89118f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72 tree clusters; noise: 70\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For every tree, detect circles on ≥3 slices.\n",
    "Reconstruct Z positions for each circle and cluster them in (x, y, z_slice).\n",
    "\"\"\"\n",
    "# Compute slice levels\n",
    "_, filt_pts = read_las_points(filtered_cloud_path)\n",
    "zmin = np.min(filt_pts[:, 2])\n",
    "slice_levels = np.arange(zmin + start_height, zmin + end_height, slice_thickness)\n",
    "\n",
    "def get_index(fname):\n",
    "    m = re.search(r\"accumulated_(\\d+)\", fname)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def z_bounds(idx):\n",
    "    i = idx - 1\n",
    "    if i < 0 or i+1 >= len(slice_levels):\n",
    "        low = slice_levels.max()\n",
    "        return float(low), float(low + 2*slice_thickness)\n",
    "    return float(slice_levels[i]), float(slice_levels[i] + 2*slice_thickness)\n",
    "\n",
    "# Build feature list for DBSCAN\n",
    "z_scale = z_scale_for_grouping\n",
    "centers, meta = [], []\n",
    "for r in rows:\n",
    "    idx = get_index(r[\"File\"])\n",
    "    if not idx: continue\n",
    "    cx, cy, rad = map(float, (r[\"CenterX\"], r[\"CenterY\"], r[\"Radius_m\"]))\n",
    "    z_low, z_up = z_bounds(idx)\n",
    "    zc = 0.5*(z_low + z_up)\n",
    "    centers.append([cx, cy, zc*z_scale])\n",
    "    meta.append(dict(center=(cx,cy), radius=rad, z_low=z_low, z_up=z_up, idx=idx))\n",
    "\n",
    "centers = np.array(centers)\n",
    "\n",
    "# DBSCAN on (x, y, scaled z)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(centers)\n",
    "labels = np.array(pcd.cluster_dbscan(eps=eps_xyz, min_points=min_slices_per_tree))\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print(f\"Found {n_clusters} tree clusters; noise: {(labels==-1).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da9aac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 72 tree bounding boxes (≥3 slices each).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build 3D bounding boxes (cylinders) for each detected tree.\n",
    "\"\"\"\n",
    "trees = []\n",
    "for lab in sorted(set(labels)):\n",
    "    if lab < 0: continue\n",
    "    ids = np.where(labels == lab)[0]\n",
    "    if len(ids) < min_slices_per_tree: continue\n",
    "    sub = [meta[i] for i in ids]\n",
    "\n",
    "    cx = np.median([s[\"center\"][0] for s in sub])\n",
    "    cy = np.median([s[\"center\"][1] for s in sub])\n",
    "    r  = np.median([s[\"radius\"] for s in sub])\n",
    "    zmin = min(s[\"z_low\"] for s in sub) - z_margin\n",
    "    zmax = max(s[\"z_up\"] for s in sub) + z_margin\n",
    "\n",
    "    trees.append(dict(center=(cx,cy), radius=r, zmin=zmin, zmax=zmax, n=len(sub)))\n",
    "print(f\"Built {len(trees)} tree bounding boxes (≥{min_slices_per_tree} slices each).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9e747e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → Rejected tree 2 (0 pts)\n",
      " → Rejected tree 4 (0 pts)\n",
      " → Rejected tree 6 (0 pts)\n",
      " → Rejected tree 10 (7 pts)\n",
      " → Rejected tree 15 (0 pts)\n",
      " → Rejected tree 16 (0 pts)\n",
      " → Rejected tree 22 (0 pts)\n",
      " → Rejected tree 26 (0 pts)\n",
      " → Rejected tree 35 (0 pts)\n",
      " → Rejected tree 36 (0 pts)\n",
      " → Rejected tree 38 (0 pts)\n",
      " → Rejected tree 42 (0 pts)\n",
      " → Rejected tree 46 (0 pts)\n",
      " → Rejected tree 47 (0 pts)\n",
      " → Rejected tree 53 (0 pts)\n",
      " → Rejected tree 56 (0 pts)\n",
      " → Rejected tree 57 (0 pts)\n",
      " → Rejected tree 58 (0 pts)\n",
      " → Rejected tree 61 (0 pts)\n",
      " → Rejected tree 62 (57 pts)\n",
      " → Rejected tree 65 (0 pts)\n",
      " → Rejected tree 68 (0 pts)\n",
      " → Rejected tree 69 (0 pts)\n",
      " → Rejected tree 70 (0 pts)\n",
      " → Rejected tree 71 (31 pts)\n",
      " → Rejected tree 72 (0 pts)\n",
      "Exported 46 tree trunks to 'Trees'.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Export 3D point clouds within each bounding box (tree trunks)\n",
    "\"\"\"\n",
    "las_filt, pts = read_las_points(filtered_cloud_path)\n",
    "exported = 0\n",
    "\n",
    "for i, t in enumerate(trees, 1):\n",
    "    cx, cy, r = t[\"center\"][0], t[\"center\"][1], t[\"radius\"]*radius_margin_factor\n",
    "    zmin, zmax = t[\"zmin\"], t[\"zmax\"]\n",
    "    dx, dy = pts[:,0]-cx, pts[:,1]-cy\n",
    "    dist = np.sqrt(dx*dx + dy*dy)\n",
    "    z = pts[:,2]\n",
    "    mask = (dist <= r) & (z >= zmin) & (z <= zmax)\n",
    "    trunk = pts[mask]\n",
    "\n",
    "    if len(trunk) < min_points_per_trunk:\n",
    "        print(f\" → Rejected tree {i} ({len(trunk)} pts)\")\n",
    "        continue\n",
    "\n",
    "    out = os.path.join(trees_dir, f\"tree_{i:03d}_trunk.laz\")\n",
    "    write_las_points(out, trunk, las_filt)\n",
    "    exported += 1\n",
    "\n",
    "print(f\"Exported {exported} tree trunks to '{trees_dir}'.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
